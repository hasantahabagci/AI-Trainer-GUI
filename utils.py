# Hasan Taha Bağcı 150210338
import json
import os
import matplotlib.pyplot as plt
from PyQt5.QtWidgets import QMessageBox

def load_metrics_from_log(log_file_path): # Function to load metrics from a JSONL file
    """Loads metrics from a JSONL file generated by train.py."""
    metrics_history = { # Initialize dictionary to store metrics
        'epochs': [],
        'train_loss': [], 'train_acc': [],
        'val_loss': [], 'val_acc': [],
        'durations': []
    }
    if not os.path.exists(log_file_path): # Check if log file exists
        print(f"Log file not found: {log_file_path}")
        return None

    with open(log_file_path, 'r') as f: # Open log file
        for line in f: # Read line by line
            try:
                entry = json.loads(line) # Parse JSON entry
                if entry.get("type") == "metric": # Check if entry is a metric
                    metrics_history['epochs'].append(entry['epoch'])
                    metrics_history['train_loss'].append(entry['train_loss'])
                    metrics_history['train_acc'].append(entry['train_acc'])
                    metrics_history['val_loss'].append(entry['val_loss'])
                    metrics_history['val_acc'].append(entry['val_acc'])
                    if 'duration_sec' in entry: # Check for duration
                         metrics_history['durations'].append(entry['duration_sec'])
            except json.JSONDecodeError: # Handle JSON decoding errors
                print(f"Warning: Skipping malformed line in {log_file_path}: {line.strip()}")
            except KeyError as e: # Handle missing keys
                print(f"Warning: Skipping line with missing key '{e}' in {log_file_path}: {line.strip()}")
    
    if not metrics_history['epochs']: # Check if any metrics were loaded
        print(f"No valid metrics found in {log_file_path}")
        return None
        
    return metrics_history

def plot_comparison(histories_dict, metric_type, output_path): # Function to plot comparison of metrics
    """
    Plots a comparison of a given metric (e.g., 'val_acc', 'val_loss') 
    from multiple training histories.
    histories_dict: {'run_id_1': history_1, 'run_id_2': history_2, ...}
    metric_type: 'train_acc', 'val_acc', 'train_loss', 'val_loss'
    """
    plt.figure(figsize=(12, 7)) # Create figure
    
    for run_id, history in histories_dict.items(): # Iterate through histories
        if history and metric_type in history and history[metric_type]:
            epochs_data = history.get('epochs', list(range(1, len(history[metric_type]) + 1))) # Get epoch data
            plt.plot(epochs_data, history[metric_type], label=f'{run_id} - {metric_type.replace("_", " ").title()}')
        else:
            print(f"Warning: Metric '{metric_type}' not found or empty for run '{run_id}'. Skipping.")

    plt.xlabel('Epochs') # Set x-axis label
    ylabel = metric_type.split('_')[-1].title() # Determine y-axis label
    if 'acc' in metric_type: ylabel += " (%)"
    plt.ylabel(ylabel) # Set y-axis label
    plt.title(f'Comparison of Model {ylabel}') # Set title
    plt.legend() # Show legend
    plt.grid(True) # Show grid
    
    try:
        plt.savefig(output_path) # Save plot
        print(f"Comparison plot saved to {output_path}")
    except Exception as e:
        print(f"Error saving comparison plot: {e}")
    plt.close() # Close plot

def show_error_message(parent, title, message): # Function to show an error message box
    """Displays an error message box."""
    msg_box = QMessageBox(parent) # Create message box
    msg_box.setIcon(QMessageBox.Critical) # Set icon
    msg_box.setWindowTitle(title) # Set title
    msg_box.setText(message) # Set text
    msg_box.setStandardButtons(QMessageBox.Ok) # Set standard buttons
    msg_box.exec_() # Execute message box

def show_info_message(parent, title, message): # Function to show an information message box
    """Displays an information message box."""
    msg_box = QMessageBox(parent) # Create message box
    msg_box.setIcon(QMessageBox.Information) # Set icon
    msg_box.setWindowTitle(title) # Set title
    msg_box.setText(message) # Set text
    msg_box.setStandardButtons(QMessageBox.Ok) # Set standard buttons
    msg_box.exec_() # Execute message box


if __name__ == '__main__':
    # Example usage of load_metrics_from_log and plot_comparison
    # Create dummy log files for testing
    dummy_results_dir = './results_dummy_utils'
    os.makedirs(dummy_results_dir, exist_ok=True)

    dummy_log1_path = os.path.join(dummy_results_dir, 'CustomCNN_20250101_120000_metrics.jsonl')
    with open(dummy_log1_path, 'w') as f:
        f.write(json.dumps({"type": "metric", "epoch": 1, "train_loss": 0.5, "train_acc": 80, "val_loss": 0.6, "val_acc": 75, "duration_sec": 60}) + '\n')
        f.write(json.dumps({"type": "metric", "epoch": 2, "train_loss": 0.4, "train_acc": 85, "val_loss": 0.5, "val_acc": 80, "duration_sec": 62}) + '\n')

    dummy_log2_path = os.path.join(dummy_results_dir, 'ResNet50_20250101_120500_metrics.jsonl')
    with open(dummy_log2_path, 'w') as f:
        f.write(json.dumps({"type": "metric", "epoch": 1, "train_loss": 0.3, "train_acc": 88, "val_loss": 0.4, "val_acc": 85, "duration_sec": 120}) + '\n')
        f.write(json.dumps({"type": "metric", "epoch": 2, "train_loss": 0.2, "train_acc": 92, "val_loss": 0.3, "val_acc": 90, "duration_sec": 125}) + '\n')

    history1 = load_metrics_from_log(dummy_log1_path)
    history2 = load_metrics_from_log(dummy_log2_path)

    if history1 and history2:
        histories_to_compare = {
            'CustomCNN_Run1': history1,
            'ResNet50_Run1': history2
        }
        plot_comparison(histories_to_compare, 'val_acc', os.path.join(dummy_results_dir, 'comparison_val_acc.png'))
        plot_comparison(histories_to_compare, 'val_loss', os.path.join(dummy_results_dir, 'comparison_val_loss.png'))
        print(f"Dummy comparison plots generated in {dummy_results_dir}")
    else:
        print("Failed to load dummy histories for comparison plot generation.")

    # Clean up dummy files
    # import shutil
    # shutil.rmtree(dummy_results_dir)
